# モデルアンサンブル実験（LightGBM + XGBoost + CatBoost）

**実行日時**: 2025-11-14
**ベースライン**: v2.6（OOF Accuracy: 85.19%）

---

## 実験概要

特徴量エンジニアリングでの最適化を一区切りとし、他の手法として**モデルアンサンブル**を試した。

### 戦略

1. v2.6の特徴量セット（16個）を使用
2. 3つの異なるGBDTアルゴリズムを訓練
   - **LightGBM**: 浅めの木で過学習を抑制
   - **XGBoost**: より強力な正則化
   - **CatBoost**: カテゴリ変数の自動処理
3. OOF AUCスコアに基づいて重み付き平均
4. 5-Fold Stratified CV

---

## 結果

### 各モデルのOOFスコア

| モデル | OOF Accuracy | OOF AUC | v2.6との差分 |
|--------|-------------|---------|------------|
| **v2.6（ベースライン）** | **85.19%** | **88.67%** | - |
| LightGBM（単体） | 85.19% | 88.67% | ±0.00pt |
| XGBoost（単体） | 83.05% | 87.78% | -2.14pt ❌ |
| CatBoost（単体） | 83.28% | 88.50% | -1.91pt ❌ |
| **アンサンブル** | **84.62%** | **88.69%** | **-0.57pt** ❌ |

### アンサンブルの重み（AUCベース）

- LightGBM: **0.335**
- XGBoost: **0.331**
- CatBoost: **0.334**

ほぼ均等な重みになってしまった。

---

## Fold別詳細

### Fold 1
- LightGBM: Acc=85.47%, AUC=90.97%
- XGBoost: Acc=82.68%, AUC=89.66%
- CatBoost: Acc=84.36%, AUC=89.85%

### Fold 2
- LightGBM: Acc=87.08%, AUC=88.50%
- XGBoost: Acc=83.15%, AUC=88.32%
- CatBoost: Acc=83.15%, AUC=89.36%

### Fold 3
- LightGBM: Acc=83.71%, AUC=87.17%
- XGBoost: Acc=82.58%, AUC=85.80%
- CatBoost: Acc=82.02%, AUC=87.80%

### Fold 4
- LightGBM: Acc=84.83%, AUC=88.57%
- XGBoost: Acc=84.27%, AUC=86.30%
- CatBoost: Acc=84.27%, AUC=88.50%

### Fold 5
- LightGBM: Acc=84.83%, AUC=88.55%
- XGBoost: Acc=82.58%, AUC=89.61%
- CatBoost: Acc=82.58%, AUC=87.71%

---

## 分析

### なぜアンサンブルが失敗したのか？

#### 1. **XGBoostとCatBoostの性能が低い**
- XGBoost: 83.05%（-2.14pt）
- CatBoost: 83.28%（-1.91pt）
- 両モデルともLightGBMより約2%低い
- 低性能モデルを混ぜることで全体が引き下げられた

#### 2. **重みがほぼ均等（0.33前後）**
- LightGBMが最高性能なのに、他のモデルと同じ重みになってしまった
- AUCスコアの差が小さく（88.67% vs 87.78% vs 88.50%）、重みに差がつかなかった
- Accuracyベースの重みづけの方が良かった可能性

#### 3. **モデルの多様性が不足**
- 3つのモデルが同じ特徴量、同じデータで訓練
- 同じような間違いをしている可能性
- 異なる視点での予測ができていない

#### 4. **データサイズの問題**
- Titanicのような小規模データセット（891サンプル）では、アンサンブルの効果が限定的
- モデルが同じパターンを学習してしまい、多様性が生まれにくい

---

## 比較: Pseudo-labeling vs アンサンブル

両方とも失敗したが、失敗の度合いが異なる：

| 手法 | OOF Accuracy | 差分（vs v2.6） | 評価 |
|------|-------------|---------------|------|
| v2.6（ベースライン） | 85.19% | - | ✅ |
| **アンサンブル** | 84.62% | **-0.57pt** | ❌ 軽度の悪化 |
| Pseudo-labeling (0.95/0.05) | 84.51% | -0.67pt | ❌ |
| Pseudo-labeling (0.90/0.10) | 83.05% | -2.13pt | ❌ 大幅悪化 |
| Pseudo-labeling (0.85/0.15) | 83.28% | -1.91pt | ❌ |

**アンサンブルの方がPseudo-labelingよりマシ**だが、どちらもベースラインを超えられなかった。

---

## 重要な発見

### LightGBM単体が最強

- LightGBM: **85.19%**（v2.6と同じ）
- XGBoost: 83.05%
- CatBoost: 83.28%

**v2.6はすでにLightGBMを使っているため、同じスコアになるのは当然。**

アンサンブルで改善を狙うなら：
1. LightGBMのハイパーパラメータを変えた複数モデル
2. 異なる特徴量セットで訓練した複数モデル
3. スタッキング（メタモデル）

---

## 提出ファイル

- **ファイル名**: `submission_ensemble.csv`
- **予測死亡率**: 64.1% (268/418)
  - v2.6の予測死亡率: 63.2%
  - 約0.9pt高め

---

## 結論

### ❌ アンサンブル失敗

**理由:**
1. XGBoost/CatBoostが低性能（-2pt程度）
2. 重みがほぼ均等で差別化できず
3. モデルの多様性不足
4. 小規模データではアンサンブルの効果が限定的

### v2.6が依然として最高スコア

- **v2.6**: 85.19% OOF Accuracy（全実験中トップ）
- 特徴量エンジニアリングでの最適化が成功

---

## 次のステップ候補

### 1. **LightGBMのハイパーパラメータ最適化（Optuna）** 🎯 推奨
- LightGBMが最高性能なので、これをさらに改善
- 期待効果: +0.3~0.7pt

### 2. **GroupKFold CV**
- 家族・チケット単位でグループ化してCV
- より堅牢な評価
- リーダーボードスコアとの乖離を減らす

### 3. **スタッキング（メタモデル）**
- 単純な重み付き平均ではなく、メタモデルで学習
- 各モデルの予測の非線形な組み合わせ

### 4. **異なる特徴量セットでのアンサンブル**
- 特徴量を変えた複数のLightGBMモデル
- より多様性のあるアンサンブル

---

## まとめ

**試した代替手法:**
1. ✅ Pseudo-labeling → 失敗（-0.67pt ~ -2.13pt）
2. ✅ モデルアンサンブル → 失敗（-0.57pt）

**現在の最高スコア:**
- **v2.6: 85.19% OOF Accuracy** 👑

次は**Optunaでのハイパーパラメータ最適化**を試すことを推奨。
