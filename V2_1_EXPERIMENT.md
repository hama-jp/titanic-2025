# v2.1実験: HasFamilyMatch削除の影響

**実験日**: 2025-11-14
**目的**: HasFamilyMatch（重要度最下位）を削除してモデルを洗練

---

## 仮説

**HasFamilyMatchは不要な特徴量である**

### 根拠

1. **Feature Importanceが極めて低い**
   - v2: 5.10（19/19位 = 最下位）
   - v3: 1.69（18/19位）
   - v3.1: 12.93（18/20位）

2. **情報の重複**
   ```python
   HasFamilyMatch = (FamilyGroupSize > FamilySize)
   ```
   - FamilyGroupSize（既存特徴量）
   - FamilySize（既存特徴量）
   - これらの比較結果でしかない

3. **GBDTは自分で学習できる**
   - 木の分岐で自動的に `FamilyGroupSize > FamilySize` を学習可能
   - わざわざフラグを作る必要なし

### 期待される効果

- ✅ ノイズ削減
- ✅ 特徴量数削減（19個 → 18個）
- ✅ CVスコア改善（または維持）

---

## 実験結果

### スコア比較

| 指標 | v2 | v2.1 | 差分 |
|------|----|----|------|
| **OOF Accuracy** | **84.18%** | 83.39% | **-0.79pt** ❌ |
| **OOF AUC** | 88.21% | **88.38%** | **+0.17pt** ✓ |
| **特徴量数** | 19 | 18 | -1 |

### Fold別詳細（Accuracy）

| Fold | v2 | v2.1 | 差分 | 評価 |
|------|----|----|------|------|
| 1 | 85.47% | 84.36% | -1.11pt | ❌ |
| 2 | 87.08% | 86.52% | -0.56pt | ≈ |
| 3 | 79.78% | **80.34%** | **+0.56pt** | ✓ |
| **4** | **84.27%** | **82.02%** | **-2.25pt** | ❌❌ |
| 5 | 84.27% | 83.71% | -0.56pt | ≈ |

**重大な発見**: Fold 4で-2.25ptの大幅低下

### 統計

| 指標 | v2 | v2.1 |
|------|----|----|
| Accuracy 平均 | 84.17% | 83.39% |
| Accuracy 標準偏差 | 2.43pt | 2.10pt |

---

## 分析

### ❌ **仮説は誤りだった**

**HasFamilyMatchを削除するとAccuracyが悪化する**

### なぜ重要度が低いのに削除すると悪化するのか？

#### 1. 特徴量間の相互作用

- HasFamilyMatch自体は重要度が低い
- しかし他の特徴量（FamilyGroupSize, FamilySize）との**相互作用**で情報を提供
- 削除すると木の分岐構造が変わり、全体のモデル性能が低下

#### 2. Feature Importanceの限界

**Gain-basedの重要度の意味**:
- 「その特徴量が単独でどれだけ貢献したか」を測定
- **他の特徴量との組み合わせでの貢献**は測れない

例えば：
- HasFamilyMatchは単独では貢献が小さい
- しかし `FamilyGroupSize > FamilySize` という**境界条件**を明示することで、木の分岐を助けている
- この「分岐を助ける効果」はGain-basedの重要度では測れない

#### 3. 小規模データの特性（891サンプル）

- データ数が少ないと、小さな変更でもスコアが大きく変動
- 特にFold 4で-2.25ptの大幅低下 = 特定のデータ分布で影響が大きい
- より多くのデータがあれば安定するが、Titanic規模では不安定

---

## Feature Importanceの詳細比較

### v2（HasFamilyMatchあり）

| Rank | Feature | Importance |
|------|---------|-----------|
| 1 | Sex | 2945.8 |
| 2 | Pclass | 893.7 |
| 3 | Title | 868.8 |
| ... | ... | ... |
| 19 | **HasFamilyMatch** | **5.1** ← 最下位 |

### v2.1（HasFamilyMatchなし）

| Rank | Feature | Importance |
|------|---------|-----------|
| 1 | Sex | 3053.2 ↑ |
| 2 | Age | 1021.8 ↑ |
| 3 | Pclass | 990.3 ↑ |
| ... | ... | ... |
| 18 | AgeBin | 0.9 |

**観察**:
- HasFamilyMatch削除後、他の特徴量の重要度が再分配された
- Sex, Age, Pclassの重要度が上昇
- しかし全体のモデル性能は低下

---

## 結論

### ❌ **v2.1は不採用**

**理由**:
- OOF Accuracy: 84.18% → 83.39%（-0.79pt）
- Fold 4で-2.25ptの大幅低下
- AUCは若干改善（+0.17pt）したが、Accuracyの低下が大きすぎる

### ✅ **v2を最終版として採用**

**理由**:
- **OOF Accuracy: 84.18%**（現時点でベスト）
- HasFamilyMatchは重要度が低くても、削除すると悪化する
- 特徴量間の相互作用が複雑

---

## 学んだ重要な教訓

### 1. **「Feature Importanceが低い = 削除すべき」ではない**

- 重要度が低くても、特徴量間の相互作用で貢献している可能性
- 削除すると木の分岐構造が変わり、予期しない影響が出る
- **削除前に必ずCVで検証すべき**

### 2. **Feature Importanceの限界を理解する**

Gain-basedの重要度は：
- ✅ その特徴量の**単独での貢献**を測定
- ❌ 他の特徴量との**組み合わせでの貢献**は測れない
- ❌ 特徴量の**補助的な役割**（分岐を助けるなど）は測れない

### 3. **小規模データでは特に慎重に**

- データ数が少ないと、小さな変更でもスコアが大きく変動
- Fold間の変動（標準偏差）を必ずチェック
- 1つのFoldだけで判断しない

### 4. **実験の価値**

- 仮説は間違っていた
- しかし実験したことで**確実な結論**が得られた
- 「やってみないと分からない」ことも多い
- **実験 → 検証 → 学習**のサイクルが重要

---

## 推奨事項

### 特徴量削減の正しいアプローチ

1. **Permutation Importanceも確認**
   - Gain-basedだけでなく、Permutation Importanceも見る
   - 特徴量をシャッフルしたときのスコア低下を測定
   - より「実質的な貢献」が分かる

2. **段階的削減**
   - 一度に複数の特徴量を削除しない
   - 1つずつ削除してCVで検証

3. **複数のメトリクスで評価**
   - AccuracyだけでなくAUCも確認
   - 両方が改善するか、少なくとも維持されるか

4. **Fold間の一貫性を確認**
   - 特定のFoldだけで大幅に悪化していないか
   - 全Foldで一貫して改善しているか

---

## 最終推奨モデル

### ✅ **v2**（OOF Acc: 84.18%）

**特徴量**（19個）:
- 数値: Age, Fare, FarePerPerson, SibSp, Parch, FamilySize, TicketGroupSize, FamilyGroupSize, CabinGroupSize
- カテゴリ: Sex, Pclass, Embarked, Title, Deck, AgeBin
- フラグ: IsAlone, IsChild, IsMother, **HasFamilyMatch** ← 保持

**提出ファイル**: `submission_restart_v2.csv`

---

## 参考: 他バージョンとの比較

| バージョン | OOF Accuracy | 特徴量数 | 備考 |
|-----------|-------------|---------|------|
| **v1** | **84.96%** | 16 | 最高Accuracy |
| **v2** | **84.18%** | 19 | 最終推奨版 |
| v2.1 | 83.39% | 18 | HasFamilyMatch削除（不採用） |
| v3 | 83.39% | 23 | 交互作用4つ（過学習） |
| v3.1 | 83.73% | 21 | 交互作用2つ |
| スタッキング | 83.95% | 19 | AUC最高（88.66%） |

---

**この実験により、Feature Importanceだけで特徴量を削除することの危険性を学びました。**
