# Titanic Perished Prediction - 最終サマリー（再スタート版）

**実施日**: 2025-11-14
**戦略**: ChatGPT共有リンクの戦略に基づく体系的アプローチ

---

## 戦略の3本柱

1. ✅ **人間としての属性を刻んだ特徴量**
   - Title / 家族 / 子供・母親

2. ✅ **グルーピング特徴量**
   - 同じ船室・チケット・家族（train+testで計算）

3. ✅ **浅めのGBDT + ちゃんとしたCV**
   - LightGBM (max_depth=4, num_leaves=16)
   - Stratified 5-Fold CV

---

## 実装したバージョン

### v1: 基本特徴量（S級＋A級）

**特徴量**（16個）:
- S級: Title, FamilySize, TicketGroupSize, FarePerPerson, Deck
- A級: AgeBin, IsChild, IsMother, 適切な欠損値補完

**結果**:
- **OOF Accuracy: 84.96%** ← 最高
- **OOF AUC: 88.41%**

**特徴**:
- シンプルで安定
- ただしtrain+testのグループ情報を一部未活用

---

### v2: train+testグループ特徴を最大限活用

**追加特徴量**（19個 = v1 + 3個）:
- **FamilyGroupSize**: Surname+FamilySizeでtrain+testから計算
- **CabinGroupSize**: Cabin共有人数をtrain+testで計算
- **HasFamilyMatch**: 同じ家族が複数見つかったかフラグ

**結果**:
- **OOF Accuracy: 84.18%**
- **OOF AUC: 88.21%**

**Feature Importance Top 3**:
1. Sex: 2945.8
2. Pclass: 893.7
3. Title: 868.8

**評価**:
- v1より若干低下（-0.78pt）
- しかしtrain+testの情報を最大限活用している戦略的に正しいアプローチ
- CabinGroupSizeが165.0（9位）で効いている

---

### v3: 交互作用特徴を追加（4つ）

**追加した交互作用**（23個 = v2 + 4個）:
1. Sex_Pclass - 救命優先度
2. Sex_AgeBin - 年齢層×性別
3. Child_Pclass - 子供×階級
4. Pclass_FarePP - 階級×実質単価

**結果**:
- **OOF Accuracy: 83.39%** ← v2より悪化
- **OOF AUC: 87.80%**

**Feature Importance（交互作用のみ）**:
- Sex_AgeBin: 332.1（8位）✅
- Sex_Pclass: 281.2（9位）✅
- Child_Pclass: 39.7（17位）❌
- Pclass_FarePP: 2.3（22位）❌

**評価**:
- 4つのうち2つのみ有効
- 特徴量が多すぎて過学習気味（23個 on 891サンプル）

---

### v3.1: 交互作用を厳選（2つのみ）

**追加した交互作用**（21個 = v2 + 2個）:
- Sex_AgeBin
- Sex_Pclass

**結果**:
- **OOF Accuracy: 83.73%**
- **OOF AUC: 88.18%**

**評価**:
- v3より改善（+0.34pt）
- しかしv2を超えられず（-0.45pt）

---

### スタッキング: LightGBM + XGBoost + CatBoost

**アーキテクチャ**:
- Level 0: LightGBM（v2設定）, XGBoost（控えめ）, CatBoost（控えめ）
- Level 1: ロジスティック回帰（L2正則化）

**ベースモデルのOOFスコア**:
- LightGBM: Acc=84.18%, AUC=88.21%
- XGBoost: Acc=82.72%, AUC=88.30%
- CatBoost: Acc=83.95%, AUC=88.52%

**スタッキング結果**:
- **OOF Accuracy: 83.95%** ← v2より低下（-0.22pt）
- **OOF AUC: 88.66%** ← v2より改善（+0.45pt）

**メタモデル係数**:
- LightGBM: 1.747
- XGBoost: 1.330
- CatBoost: 2.460 ← 最も高い重み

**評価**:
- AUCは改善したがAccuracyは低下
- データ数が少ない（891）ため、アンサンブルの効果が限定的
- 「小さいデータでのアンサンブルの罠」を体験

---

## 全バージョン比較

| バージョン | OOF Accuracy | OOF AUC | 特徴量数 | 評価 |
|-----------|-------------|---------|---------|------|
| **v1** | **84.96%** | 88.41% | 16 | ✅ 最高Accuracy |
| **v2** | 84.18% | 88.21% | 19 | ✅ 戦略的に正しい |
| v3 | 83.39% | 87.80% | 23 | ❌ 過学習気味 |
| v3.1 | 83.73% | 88.18% | 21 | △ v3より改善 |
| **スタッキング** | 83.95% | **88.66%** | 19 | △ AUCは最高 |

---

## 学んだ教訓

### 1. 特徴量エンジニアリング

**効果的だったもの**:
- ✅ Title抽出（Mr/Mrs/Miss/Master/Officer/Noble）
- ✅ FarePerPerson（Fare / TicketGroupSize）
- ✅ TicketGroupSize（train+testで計算）
- ✅ CabinGroupSize（train+testで計算）

**効果が限定的だったもの**:
- ❌ 交互作用特徴（Sex_AgeBin, Sex_Pclass以外）
- ❌ HasFamilyMatch（重要度が低い）

**重要な洞察**:
- **train+testを結合してグループサイズを計算**するのは強力
- ただし「生存率」のようなターゲット情報は使わない（リーク）
- Titanic規模（891サンプル）では**15-20特徴量が適正**

### 2. 交互作用特徴

**成功例**:
- Sex_AgeBin（重要度332.1, 8位）
- Sex_Pclass（重要度281.2, 9位）

**失敗例**:
- Child_Pclass（重要度39.7, 17位）
- Pclass_FarePP（重要度2.3, 22位）

**教訓**:
- **やみくもに交互作用を追加すると逆効果**
- ドメイン知識で「確実に効く」ものだけ厳選
- 重要度の低いものは潔く捨てる

### 3. モデルアンサンブル

**スタッキングの罠**:
- データ数が少ないと、アンサンブルの効果が限定的
- AUCは改善してもAccuracyは低下することがある
- メタモデルが単体ベストモデルより劣ることもある

**対策**:
- **ベースモデルを控えめ設定**にする（アンダーフィット寄り）
- メタモデルは**ロジスティック回帰1本**に留める
- CVでの改善が**全Foldで一貫**していることを確認

### 4. CVとLBの関係

**データ数が少ない場合**:
- CVスコアの0.5pt程度の差は**誤差の範囲**
- Fold間の変動（標準偏差）を必ずチェック
- **全Foldで平均的に改善**する方が信頼できる

---

## 最終推奨モデル

### 推奨1: **v1**（Accuracy重視）

**理由**:
- **OOF Accuracy: 84.96%**（全バージョン中最高）
- シンプルで安定（16特徴量）
- 過学習のリスクが最も低い

**使用ケース**:
- 安定性を最優先
- シンプルさ重視

---

### 推奨2: **v2**（戦略重視）

**理由**:
- **train+testの情報を最大限活用**（戦略的に正しい）
- OOF Accuracy: 84.18%（v1より若干低いが許容範囲）
- CabinGroupSizeなど有効な特徴を含む

**使用ケース**:
- テスト分布が訓練と異なる可能性がある場合
- グループ情報が重要な問題

---

### 推奨3: **スタッキング**（AUC重視）

**理由**:
- **OOF AUC: 88.66%**（全バージョン中最高）
- 確率予測としては最も精度が高い
- Accuracyは若干低い（83.95%）

**使用ケース**:
- AUCで評価される場合
- 確率予測が重要な場合

---

## 提出ファイル

| ファイル | モデル | OOF Accuracy | 予測死亡率 |
|---------|--------|-------------|-----------|
| `submission_restart.csv` | v1 | 84.96% | 63.4% |
| `submission_restart_v2.csv` | v2 | 84.18% | 62.9% |
| `submission_restart_v3.csv` | v3 | 83.39% | 63.2% |
| `submission_restart_v3_1.csv` | v3.1 | 83.73% | 62.7% |
| `submission_stacking.csv` | スタッキング | 83.95% | 63.4% |

---

## まとめ

### ✅ 達成したこと

1. **戦略の3本柱を完全実装**
   - 人間属性特徴量（Title, FamilySize, IsChild, IsMother）
   - グルーピング特徴量（train+testで計算）
   - 浅めのGBDT + Stratified K-Fold CV

2. **体系的な実験**
   - v1（基本）→ v2（train+test活用）→ v3（交互作用）→ v3.1（厳選）→ スタッキング
   - 各ステップで改善点と問題点を明確化

3. **実践的な知見の獲得**
   - 小規模データでの特徴量エンジニアリング
   - 交互作用の選定基準
   - アンサンブルの限界

### 🎯 最終結論

**v1（OOF Acc: 84.96%）またはv2（OOF Acc: 84.18%）を推奨**

- v1: 最高のCVスコア、シンプル、安定
- v2: 戦略的に正しい、train+test情報を活用

スタッキングはAUC重視の場合に検討。

---

## 次のステップ（オプション）

もしさらに改善するなら:

1. **Seedアンサンブル**
   - v1またはv2を異なるseed（42, 123, 456, 789, 2024）で訓練
   - 5つのモデルの平均を取る
   - スタッキングより軽量で安定する可能性

2. **閾値最適化**
   - スタッキング版は0.5以外の閾値で改善する可能性
   - CVでの最適閾値を探索

3. **実際のLBで検証**
   - 全バージョンを提出
   - LBスコアで最終判断

---

**プロジェクト完了！** 🎉

戦略的アプローチに基づき、体系的な実験を通じて高精度なモデルを構築できました。
