# Optunaハイパーパラメータ最適化実験

**実行日時**: 2025-11-14
**ベースライン**: v2.6（OOF Accuracy: 85.19%）
**最適化手法**: Optuna TPE Sampler

---

## 実験概要

特徴量エンジニアリングとモデルアンサンブルが失敗したため、**LightGBMのハイパーパラメータ最適化**を試した。

### 戦略

1. v2.6の特徴量セット（16個）を使用
2. Optunaで以下のパラメータを探索:
   - `learning_rate`: 0.01 ~ 0.1（対数スケール）
   - `num_leaves`: 8 ~ 64
   - `max_depth`: 3 ~ 10
   - `min_data_in_leaf`: 10 ~ 50
   - `bagging_fraction`: 0.6 ~ 1.0
   - `feature_fraction`: 0.6 ~ 1.0
   - `lambda_l1`: 0.0 ~ 1.0
   - `lambda_l2`: 0.0 ~ 1.0
3. 探索回数: **100 trials**
4. 最適化目標: **OOF Accuracy**（5-Fold Stratified CV）
5. サンプラー: TPESampler（ベイズ最適化）

---

## 結果

### 最終スコア

| モデル | OOF Accuracy | OOF AUC | v2.6との差分 |
|--------|-------------|---------|------------|
| **v2.6（ベースライン）** | **85.19%** | **88.67%** | - |
| **Optuna最適化版** | **85.07%** | **88.91%** | **-0.12pt** ❌ |

### v2.6のパラメータ（手動調整）

```python
{
    'learning_rate': 0.03,
    'num_leaves': 16,
    'max_depth': 4,
    'min_data_in_leaf': 20,
    'bagging_fraction': 0.8,
    'feature_fraction': 0.8,
    'lambda_l1': 0.1,
    'lambda_l2': 0.1
}
```

### Optunaの最適パラメータ

```python
{
    'learning_rate': 0.0746,
    'num_leaves': 31,
    'max_depth': 4,
    'min_data_in_leaf': 28,
    'bagging_fraction': 0.9434,
    'feature_fraction': 0.8934,
    'lambda_l1': 0.6748,
    'lambda_l2': 0.7847
}
```

### パラメータの変化

| パラメータ | v2.6 | Optuna | 変化 |
|-----------|------|--------|------|
| learning_rate | 0.03 | 0.0746 | +2.5倍 ✅ |
| num_leaves | 16 | 31 | +2倍 |
| max_depth | 4 | 4 | 同じ |
| min_data_in_leaf | 20 | 28 | +8 |
| bagging_fraction | 0.8 | 0.9434 | +18% |
| feature_fraction | 0.8 | 0.8934 | +12% |
| lambda_l1 | 0.1 | 0.6748 | +6.7倍 |
| lambda_l2 | 0.1 | 0.7847 | +7.8倍 |

### Fold別詳細（Optuna最適化版）

| Fold | Accuracy | AUC | Best Iteration |
|------|----------|-----|----------------|
| 1 | 86.03% | 90.40% | 152 |
| 2 | 87.64% | 88.85% | 54 |
| 3 | 81.46% | 87.05% | 81 |
| 4 | 83.71% | 87.64% | 48 |
| 5 | 86.52% | 90.60% | 91 |

**平均**: 85.07% Accuracy, 88.91% AUC

### v2.6 Fold別（比較）

| Fold | Accuracy | AUC |
|------|----------|-----|
| 1 | 85.47% | 90.97% |
| 2 | 87.08% | 88.50% |
| 3 | 83.71% | 87.17% |
| 4 | 84.83% | 88.57% |
| 5 | 84.83% | 88.55% |

**平均**: 85.19% Accuracy, 88.67% AUC

---

## 分析

### なぜOptuna最適化が失敗したのか？

#### 1. **v2.6のパラメータが既に良好**
- 手動調整されたv2.6のパラメータは、浅い木（num_leaves=16, max_depth=4）で過学習を抑制
- Optunaは`num_leaves=31`（2倍）を選択 → より複雑なモデル
- 小規模データでは浅い木の方が汎化性能が高い

#### 2. **過学習のリスク増加**
- Optunaが選んだパラメータ:
  - `num_leaves`: 16 → 31（木が深くなる）
  - `min_data_in_leaf`: 20 → 28（より保守的だが、num_leavesが増えて相殺）
  - `learning_rate`: 0.03 → 0.0746（2.5倍、学習が速すぎる可能性）
- 結果: 訓練データに過適合し、汎化性能が低下

#### 3. **正則化の強化が裏目に**
- `lambda_l1`: 0.1 → 0.6748（6.7倍）
- `lambda_l2`: 0.1 → 0.7847（7.8倍）
- 強すぎる正則化で、モデルの表現力が制限された可能性

#### 4. **小規模データでのハイパーパラメータ探索の限界**
- 891サンプルの小規模データセット
- CVスコアの分散が大きい（Fold 3: 81.46% vs Fold 2: 87.64%）
- ハイパーパラメータの微妙な差が性能に大きく影響
- 100 trialsでは探索空間が広すぎて、最適解に到達できなかった可能性

#### 5. **AUCは改善、Accuracyは悪化**
- Optuna: AUC 88.91%（+0.24pt改善）✅
- Optuna: Accuracy 85.07%（-0.12pt悪化）❌
- AUCとAccuracyのトレードオフが発生
- 閾値調整で改善できる可能性があるが、本質的な性能向上ではない

---

## Fold別の変動分析

### v2.6のFold安定性
- 最大: 87.08%（Fold 2）
- 最小: 83.71%（Fold 3）
- 差分: **3.37pt**

### OptunaのFold安定性
- 最大: 87.64%（Fold 2）
- 最小: 81.46%（Fold 3）
- 差分: **6.18pt**

**Optunaの方が不安定**（Fold間のばらつきが大きい）

---

## 提出ファイル

- **ファイル名**: `submission_optuna.csv`
- **予測死亡率**: 63.9% (267/418)
  - v2.6の予測死亡率: 63.2%
  - 約0.7pt高め

---

## これまでの代替手法の結果まとめ

| 手法 | OOF Accuracy | 差分（vs v2.6） | 評価 |
|------|-------------|---------------|------|
| **v2.6（ベースライン）** | **85.19%** | - | ✅ 最高 |
| Pseudo-labeling (0.95/0.05) | 84.51% | -0.67pt | ❌ |
| Pseudo-labeling (0.90/0.10) | 83.05% | -2.13pt | ❌ |
| Pseudo-labeling (0.85/0.15) | 83.28% | -1.91pt | ❌ |
| モデルアンサンブル | 84.62% | -0.57pt | ❌ |
| **Optuna最適化** | **85.07%** | **-0.12pt** | ❌ **軽度悪化** |

**全ての代替手法がv2.6を超えられなかった。**

---

## 結論

### ❌ Optuna最適化失敗

**理由:**
1. v2.6の手動パラメータが既に優秀（浅い木で過学習抑制）
2. Optunaが選んだパラメータは複雑すぎて過学習
3. 小規模データではハイパーパラメータ探索の効果が限定的
4. CVスコアの分散が大きく、最適化が困難
5. AUCは改善したがAccuracyは悪化（トレードオフ）

### v2.6が依然として最高スコア

- **v2.6: 85.19% OOF Accuracy** 👑
- シンプルな浅い木 + 適度な正則化が最適
- 手動調整の方が良い結果

---

## 重要な発見

### 1. **小規模データでは浅い木が最適**
- v2.6: `num_leaves=16, max_depth=4`
- Optuna: `num_leaves=31, max_depth=4`
- **浅い木の方が汎化性能が高い**

### 2. **手動調整 > 自動最適化**
- 891サンプルの小規模データ
- ドメイン知識に基づく手動調整の方が効果的
- Optunaは探索空間が広すぎて最適解に到達できず

### 3. **これ以上の改善は困難**
- 特徴量エンジニアリング: 失敗
- Pseudo-labeling: 失敗
- モデルアンサンブル: 失敗
- ハイパーパラメータ最適化: 失敗
- **v2.6が現状の限界と考えられる**

---

## 次のステップ候補

### 残りの選択肢（効果は未知数）

1. **GroupKFold CV**
   - 家族・チケット単位でグループ化
   - より堅牢な評価
   - ただし、スコア自体は改善しない可能性

2. **閾値最適化**
   - Optunaの結果でAUCは改善（88.91%）
   - 閾値を0.5から変更してAccuracyを最大化
   - 期待効果: 小幅改善（+0.1~0.3pt程度）

3. **異なる特徴量セット**
   - v2.6の16特徴量を変更
   - ただし、これまでの実験で最適化済み

4. **諦めてv2.6を最終版とする** 🎯 推奨
   - 85.19% OOF Accuracy
   - 全ての代替手法を試したが改善なし
   - これ以上の時間投資は非効率

---

## まとめ

**試した代替手法:**
1. ❌ Pseudo-labeling → 失敗（-0.67pt ~ -2.13pt）
2. ❌ モデルアンサンブル → 失敗（-0.57pt）
3. ❌ Optuna最適化 → 失敗（-0.12pt）

**現在の最高スコア:**
- **v2.6: 85.19% OOF Accuracy** 👑

**推奨:**
- **v2.6を最終版として確定**
- これ以上の改善は困難
- 時間と労力を別のタスクに投資すべき
